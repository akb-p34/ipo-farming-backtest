{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ IPO Farming Complete Backtest System\n",
    "\n",
    "**Professional-grade backtesting with train/test split, S&P 500 benchmarking, and PDF reporting**\n",
    "\n",
    "## üìã Prerequisites & Data Requirements\n",
    "\n",
    "### Required Files:\n",
    "1. **IPO-age.xlsx** - Jay Ritter's IPO database (1975-2024)\n",
    "   - Download from: [Jay Ritter's IPO Data](https://site.warrington.ufl.edu/ritter/ipo-data/)\n",
    "   - Place in the same directory as this notebook\n",
    "   - Contains: IPO dates, tickers, prices, and company information\n",
    "\n",
    "### System Requirements:\n",
    "- Python 3.9+\n",
    "- 8GB+ RAM recommended for processing 20+ years of data\n",
    "- Internet connection for market data and status checks\n",
    "\n",
    "## üéØ What This Does:\n",
    "1. Loads ALL IPOs from 2000-2025 (including delisted)\n",
    "2. Splits data 50/50 for training and testing\n",
    "3. Optimizes entry/exit times on training set\n",
    "4. Validates strategy on test set (no look-ahead bias)\n",
    "5. Simulates $100K portfolio over entire period\n",
    "6. Compares performance to S&P 500 benchmark\n",
    "7. Calculates proper risk metrics (Sortino, Max Drawdown)\n",
    "8. Generates professional PDF report with all results\n",
    "\n",
    "## üìä Key Features:\n",
    "- **No Annualization Errors** - Raw period returns only\n",
    "- **Train/Test Split** - Proper out-of-sample validation\n",
    "- **Organized Outputs** - Timestamped folders with subfolders\n",
    "- **PDF Reports** - Professional documentation of results\n",
    "- **S&P 500 Benchmark** - Direct performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'seaborn': 'seaborn',\n",
    "    'yfinance': 'yfinance',\n",
    "    'openpyxl': 'openpyxl',\n",
    "    'pytz': 'pytz',\n",
    "    'tqdm': 'tqdm',\n",
    "    'reportlab': 'reportlab',\n",
    "    'ib_insync': 'ib-insync'\n",
    "}\n",
    "\n",
    "for import_name, install_name in packages.items():\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"‚úì {import_name} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {install_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", install_name])\n",
    "        print(f\"‚úì {install_name} installed\")\n",
    "\n",
    "print(\"\\n‚úÖ All packages ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import yfinance as yf\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CONFIGURATION - MODIFY THESE PARAMETERS AS NEEDED\n",
    "CONFIG = {\n",
    "    # Date Range\n",
    "    'START_YEAR': 2000,\n",
    "    'END_YEAR': 2025,\n",
    "    'END_DATE': '2025-09-23',\n",
    "    \n",
    "    # Portfolio Settings\n",
    "    'INITIAL_CAPITAL': 100_000,\n",
    "    'TRAIN_TEST_SPLIT': 0.5,  # 50/50 split\n",
    "    \n",
    "    # Data Settings\n",
    "    'DATA_SOURCE': 'HYBRID',  # 'SIMULATION', 'YAHOO', 'IBKR', 'HYBRID'\n",
    "    'USE_CACHE': True,  # Cache downloaded data\n",
    "    \n",
    "    # Analysis Settings\n",
    "    'MIN_TICKERS_PER_WINDOW': 10,  # Minimum tickers for valid window\n",
    "    'CONFIDENCE_LEVEL': 0.95,  # For VaR calculations\n",
    "    \n",
    "    # Benchmark\n",
    "    'BENCHMARK': 'SPY',  # S&P 500 ETF\n",
    "    \n",
    "    # Output Settings\n",
    "    'GENERATE_PDF': True,\n",
    "    'SAVE_INTERMEDIATE': True,\n",
    "    \n",
    "    # IBKR Settings (if using)\n",
    "    'IBKR': {\n",
    "        'HOST': '127.0.0.1',\n",
    "        'PORT': 7497,\n",
    "        'CLIENT_ID': random.randint(1, 999),\n",
    "        'REQUEST_DELAY': 5.0,\n",
    "        'MAX_RETRIES': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create timestamped output directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "test_name = f\"backtest_{timestamp}\"\n",
    "output_dir = Path('outputs') / test_name\n",
    "\n",
    "# Create organized subdirectories\n",
    "subdirs = ['config', 'data', 'analysis', 'reports', 'visualizations', 'logs']\n",
    "for subdir in subdirs:\n",
    "    (output_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "with open(output_dir / 'config' / 'test_config.json', 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üéØ Configuration set!\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "print(f\"üìÖ Date range: {CONFIG['START_YEAR']}-01-01 to {CONFIG['END_DATE']}\")\n",
    "print(f\"üí∞ Initial capital: ${CONFIG['INITIAL_CAPITAL']:,}\")\n",
    "print(f\"üìä Train/Test split: {CONFIG['TRAIN_TEST_SPLIT']*100:.0f}%/{(1-CONFIG['TRAIN_TEST_SPLIT'])*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load IPO Universe (2000-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ipo_universe():\n",
    "    \"\"\"Load IPO data from Jay Ritter database and classify active/delisted\"\"\"\n",
    "    \n",
    "    print(\"üìö Loading IPO universe from database...\")\n",
    "    \n",
    "    try:\n",
    "        # Load Jay Ritter's IPO database\n",
    "        df = pd.read_excel('IPO-age.xlsx', sheet_name='1975-2024', dtype={'offer date': str})\n",
    "        \n",
    "        # Parse dates\n",
    "        df['IPO_Date'] = pd.to_datetime(df['offer date'], format='%Y%m%d', errors='coerce')\n",
    "        \n",
    "        # Filter by date range\n",
    "        start_date = f\"{CONFIG['START_YEAR']}-01-01\"\n",
    "        df = df[(df['IPO_Date'] >= start_date) & (df['IPO_Date'] <= CONFIG['END_DATE'])]\n",
    "        \n",
    "        # Clean and prepare data\n",
    "        df = df.dropna(subset=['Ticker'])\n",
    "        df['Ticker'] = df['Ticker'].astype(str).str.strip().str.upper()\n",
    "        \n",
    "        # Rename columns\n",
    "        df = df.rename(columns={\n",
    "            'IPO name': 'Company',\n",
    "            'Offer Price': 'IPO_Price',\n",
    "            'Proceeds ($mil)': 'Proceeds_Mil'\n",
    "        })\n",
    "        \n",
    "        # Handle missing prices\n",
    "        df['IPO_Price'] = pd.to_numeric(df['IPO_Price'], errors='coerce')\n",
    "        median_price = df['IPO_Price'].median()\n",
    "        df['IPO_Price'].fillna(median_price, inplace=True)\n",
    "        \n",
    "        # Select relevant columns\n",
    "        columns = ['Ticker', 'Company', 'IPO_Date', 'IPO_Price']\n",
    "        if 'Proceeds_Mil' in df.columns:\n",
    "            columns.append('Proceeds_Mil')\n",
    "        \n",
    "        universe = df[columns].copy()\n",
    "        \n",
    "        print(f\"‚úì Loaded {len(universe)} IPOs from {CONFIG['START_YEAR']} to {CONFIG['END_YEAR']}\")\n",
    "        \n",
    "        return universe\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå ERROR: IPO-age.xlsx not found!\")\n",
    "        print(\"Please download from: https://site.warrington.ufl.edu/ritter/ipo-data/\")\n",
    "        print(\"\\nUsing sample data for demonstration...\")\n",
    "        \n",
    "        # Sample data for demonstration\n",
    "        sample_data = [\n",
    "            ('GOOGL', 'Alphabet Inc', '2004-08-19', 85.00),\n",
    "            ('META', 'Meta Platforms', '2012-05-18', 38.00),\n",
    "            ('UBER', 'Uber', '2019-05-10', 45.00),\n",
    "            ('ABNB', 'Airbnb', '2020-12-10', 68.00),\n",
    "            ('SNOW', 'Snowflake', '2020-09-16', 120.00),\n",
    "            ('COIN', 'Coinbase', '2021-04-14', 250.00),\n",
    "            ('HOOD', 'Robinhood', '2021-07-29', 38.00),\n",
    "            ('RIVN', 'Rivian', '2021-11-10', 78.00),\n",
    "        ] * 5  # Replicate for demonstration\n",
    "        \n",
    "        universe = pd.DataFrame(sample_data, columns=['Ticker', 'Company', 'IPO_Date', 'IPO_Price'])\n",
    "        universe['IPO_Date'] = pd.to_datetime(universe['IPO_Date'])\n",
    "        universe = universe.drop_duplicates()\n",
    "        \n",
    "        return universe\n",
    "\n",
    "# Load IPO universe\n",
    "ipo_universe = load_ipo_universe()\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nüìä IPO Universe Summary:\")\n",
    "print(f\"   Total IPOs: {len(ipo_universe)}\")\n",
    "print(f\"   Date range: {ipo_universe['IPO_Date'].min().date()} to {ipo_universe['IPO_Date'].max().date()}\")\n",
    "print(f\"   Average IPO price: ${ipo_universe['IPO_Price'].mean():.2f}\")\n",
    "\n",
    "# Show distribution by year\n",
    "ipo_universe['Year'] = ipo_universe['IPO_Date'].dt.year\n",
    "yearly_counts = ipo_universe.groupby('Year').size()\n",
    "\n",
    "print(f\"\\nüìÖ IPOs by Year:\")\n",
    "for year, count in yearly_counts.head(10).items():\n",
    "    print(f\"   {year}: {count} IPOs\")\n",
    "if len(yearly_counts) > 10:\n",
    "    print(f\"   ... and {len(yearly_counts)-10} more years\")\n",
    "\n",
    "ipo_universe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Classify Active vs Delisted Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ticker_status(universe):\n",
    "    \"\"\"Check current trading status of each ticker\"\"\"\n",
    "    \n",
    "    print(\"\\nüîç Classifying ticker status (Active/Delisted)...\")\n",
    "    \n",
    "    # Initialize status column\n",
    "    universe['Status'] = 'Unknown'\n",
    "    \n",
    "    # Check status in batches to avoid rate limits\n",
    "    batch_size = 50\n",
    "    \n",
    "    for i in tqdm(range(0, len(universe), batch_size), desc=\"Checking status\"):\n",
    "        batch = universe.iloc[i:i+batch_size]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            ticker = row['Ticker']\n",
    "            \n",
    "            try:\n",
    "                # Try to get recent data\n",
    "                stock = yf.Ticker(ticker)\n",
    "                hist = stock.history(period='1d')\n",
    "                \n",
    "                if not hist.empty:\n",
    "                    universe.loc[idx, 'Status'] = 'Active'\n",
    "                else:\n",
    "                    # Try to get info as fallback\n",
    "                    info = stock.info\n",
    "                    if info and 'symbol' in info:\n",
    "                        universe.loc[idx, 'Status'] = 'Active'\n",
    "                    else:\n",
    "                        universe.loc[idx, 'Status'] = 'Delisted'\n",
    "            except:\n",
    "                universe.loc[idx, 'Status'] = 'Delisted'\n",
    "    \n",
    "    # Separate active and delisted\n",
    "    active_ipos = universe[universe['Status'] == 'Active'].copy()\n",
    "    delisted_ipos = universe[universe['Status'] == 'Delisted'].copy()\n",
    "    \n",
    "    # Save to files\n",
    "    universe.to_csv(output_dir / 'data' / 'combined_universe.csv', index=False)\n",
    "    active_ipos.to_csv(output_dir / 'data' / 'active_ipos.csv', index=False)\n",
    "    delisted_ipos.to_csv(output_dir / 'data' / 'delisted_ipos.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Classification Complete:\")\n",
    "    print(f\"   Active: {len(active_ipos)} ({len(active_ipos)/len(universe)*100:.1f}%)\")\n",
    "    print(f\"   Delisted: {len(delisted_ipos)} ({len(delisted_ipos)/len(universe)*100:.1f}%)\")\n",
    "    print(f\"   Unknown: {(universe['Status'] == 'Unknown').sum()}\")\n",
    "    \n",
    "    print(f\"\\nüíæ Files saved:\")\n",
    "    print(f\"   ‚Ä¢ combined_universe.csv\")\n",
    "    print(f\"   ‚Ä¢ active_ipos.csv\")\n",
    "    print(f\"   ‚Ä¢ delisted_ipos.csv\")\n",
    "    \n",
    "    return universe, active_ipos, delisted_ipos\n",
    "\n",
    "# Classify tickers\n",
    "ipo_universe, active_ipos, delisted_ipos = classify_ticker_status(ipo_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(universe):\n",
    "    \"\"\"Split IPOs chronologically for proper backtesting\"\"\"\n",
    "    \n",
    "    # Sort by IPO date\n",
    "    universe = universe.sort_values('IPO_Date').reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split point\n",
    "    split_idx = int(len(universe) * CONFIG['TRAIN_TEST_SPLIT'])\n",
    "    \n",
    "    # Create splits\n",
    "    train_set = universe.iloc[:split_idx].copy()\n",
    "    test_set = universe.iloc[split_idx:].copy()\n",
    "    \n",
    "    # Get date ranges\n",
    "    train_start = train_set['IPO_Date'].min()\n",
    "    train_end = train_set['IPO_Date'].max()\n",
    "    test_start = test_set['IPO_Date'].min()\n",
    "    test_end = test_set['IPO_Date'].max()\n",
    "    \n",
    "    # Save split information\n",
    "    split_info = {\n",
    "        'total_ipos': len(universe),\n",
    "        'train_size': len(train_set),\n",
    "        'test_size': len(test_set),\n",
    "        'train_date_range': f\"{train_start.date()} to {train_end.date()}\",\n",
    "        'test_date_range': f\"{test_start.date()} to {test_end.date()}\",\n",
    "        'train_active': (train_set['Status'] == 'Active').sum(),\n",
    "        'train_delisted': (train_set['Status'] == 'Delisted').sum(),\n",
    "        'test_active': (test_set['Status'] == 'Active').sum(),\n",
    "        'test_delisted': (test_set['Status'] == 'Delisted').sum()\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'analysis' / 'train_test_split.json', 'w') as f:\n",
    "        json.dump(split_info, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"üìä Train/Test Split:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüéØ TRAINING SET:\")\n",
    "    print(f\"   Size: {len(train_set)} IPOs\")\n",
    "    print(f\"   Period: {train_start.date()} to {train_end.date()}\")\n",
    "    print(f\"   Active: {split_info['train_active']}, Delisted: {split_info['train_delisted']}\")\n",
    "    \n",
    "    print(f\"\\nüß™ TEST SET:\")\n",
    "    print(f\"   Size: {len(test_set)} IPOs\")\n",
    "    print(f\"   Period: {test_start.date()} to {test_end.date()}\")\n",
    "    print(f\"   Active: {split_info['test_active']}, Delisted: {split_info['test_delisted']}\")\n",
    "    \n",
    "    print(f\"\\nüí° No overlap - strictly chronological split\")\n",
    "    \n",
    "    return train_set, test_set, split_info\n",
    "\n",
    "# Create train/test split\n",
    "train_set, test_set, split_info = create_train_test_split(ipo_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Data Collection for IPOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ipo_day_data(ticker, ipo_date):\n",
    "    \"\"\"Fetch or simulate IPO day intraday data\"\"\"\n",
    "    \n",
    "    if CONFIG['DATA_SOURCE'] in ['YAHOO', 'HYBRID']:\n",
    "        try:\n",
    "            # Try Yahoo Finance for IPO day data\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Get 1-minute data for IPO day\n",
    "            start = ipo_date\n",
    "            end = ipo_date + timedelta(days=1)\n",
    "            \n",
    "            df = stock.history(start=start, end=end, interval='1m')\n",
    "            \n",
    "            if not df.empty and len(df) > 100:  # Need sufficient data\n",
    "                df.reset_index(inplace=True)\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "                return df\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Fallback to simulation\n",
    "    return simulate_ipo_day_data(ticker, ipo_date)\n",
    "\n",
    "def simulate_ipo_day_data(ticker, ipo_date, ipo_price=None):\n",
    "    \"\"\"Generate realistic simulated IPO day data\"\"\"\n",
    "    \n",
    "    np.random.seed(hash(ticker) % 2**32)\n",
    "    \n",
    "    if ipo_price is None:\n",
    "        ipo_price = np.random.uniform(10, 100)\n",
    "    \n",
    "    # IPO day characteristics\n",
    "    opening_pop = np.random.uniform(0.9, 1.5)  # Opening pop/drop\n",
    "    volatility = np.random.uniform(0.003, 0.01)\n",
    "    trend = np.random.uniform(-0.0003, 0.0005)\n",
    "    \n",
    "    # Generate trading day timestamps\n",
    "    eastern = pytz.timezone('America/New_York')\n",
    "    start = pd.Timestamp(ipo_date).replace(hour=9, minute=30)\n",
    "    end = pd.Timestamp(ipo_date).replace(hour=16, minute=0)\n",
    "    timestamps = pd.date_range(start, end, freq='1min', tz=eastern)\n",
    "    \n",
    "    # Generate price series\n",
    "    open_price = ipo_price * opening_pop\n",
    "    prices = [open_price]\n",
    "    \n",
    "    for i in range(1, len(timestamps)):\n",
    "        hour = timestamps[i].hour\n",
    "        \n",
    "        # Intraday volatility patterns\n",
    "        if hour < 10:  # Opening hour - high volatility\n",
    "            vol_mult = 1.5\n",
    "        elif hour < 12:  # Morning\n",
    "            vol_mult = 1.2\n",
    "        elif hour < 14:  # Midday - lower volatility\n",
    "            vol_mult = 0.8\n",
    "        else:  # Afternoon\n",
    "            vol_mult = 1.1\n",
    "        \n",
    "        change = np.random.normal(trend, volatility * vol_mult)\n",
    "        new_price = prices[-1] * (1 + change)\n",
    "        prices.append(max(new_price, ipo_price * 0.5))  # Floor at 50% of IPO price\n",
    "    \n",
    "    # Create OHLCV data\n",
    "    df = pd.DataFrame({\n",
    "        'datetime': timestamps,\n",
    "        'open': prices,\n",
    "        'high': np.array(prices) * (1 + np.abs(np.random.normal(0, 0.002, len(prices)))),\n",
    "        'low': np.array(prices) * (1 - np.abs(np.random.normal(0, 0.002, len(prices)))),\n",
    "        'close': prices,\n",
    "        'volume': np.random.gamma(2, 100000, len(prices)).astype(int)\n",
    "    })\n",
    "    \n",
    "    # Ensure OHLC consistency\n",
    "    df['high'] = df[['open', 'high', 'close']].max(axis=1)\n",
    "    df['low'] = df[['open', 'low', 'close']].min(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def collect_ipo_data(universe_subset, desc=\"Collecting data\"):\n",
    "    \"\"\"Collect IPO day data for a subset of the universe\"\"\"\n",
    "    \n",
    "    data_dict = {}\n",
    "    failed = []\n",
    "    \n",
    "    for _, row in tqdm(universe_subset.iterrows(), total=len(universe_subset), desc=desc):\n",
    "        ticker = row['Ticker']\n",
    "        ipo_date = row['IPO_Date']\n",
    "        ipo_price = row.get('IPO_Price', None)\n",
    "        \n",
    "        try:\n",
    "            if CONFIG['DATA_SOURCE'] == 'SIMULATION':\n",
    "                df = simulate_ipo_day_data(ticker, ipo_date, ipo_price)\n",
    "            else:\n",
    "                df = fetch_ipo_day_data(ticker, ipo_date)\n",
    "            \n",
    "            if df is not None and len(df) > 0:\n",
    "                data_dict[ticker] = df\n",
    "            else:\n",
    "                failed.append(ticker)\n",
    "        except Exception as e:\n",
    "            failed.append(ticker)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data collection complete:\")\n",
    "    print(f\"   Successful: {len(data_dict)}\")\n",
    "    print(f\"   Failed: {len(failed)}\")\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Collect data for training set\n",
    "print(\"\\nüì° Collecting IPO day data...\")\n",
    "print(f\"Data source: {CONFIG['DATA_SOURCE']}\\n\")\n",
    "\n",
    "train_data = collect_ipo_data(train_set, \"Training set\")\n",
    "test_data = collect_ipo_data(test_set, \"Test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Window Optimization on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trading_windows(data_dict, desc=\"Analyzing\"):\n",
    "    \"\"\"Find optimal entry/exit times using training data\"\"\"\n",
    "    \n",
    "    # Generate all possible 30-minute interval windows\n",
    "    times = []\n",
    "    for hour in range(9, 16):\n",
    "        for minute in [0, 30]:\n",
    "            if hour == 9 and minute == 0:\n",
    "                continue  # Market opens at 9:30\n",
    "            if hour == 16 and minute == 30:\n",
    "                continue  # Market closes at 16:00\n",
    "            times.append(f\"{hour:02d}:{minute:02d}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test all window combinations\n",
    "    total_windows = sum(1 for i in range(len(times)-1) for _ in times[i+1:])\n",
    "    \n",
    "    with tqdm(total=total_windows, desc=desc) as pbar:\n",
    "        for i, buy_time_str in enumerate(times[:-1]):\n",
    "            for sell_time_str in times[i+1:]:\n",
    "                buy_time = pd.to_datetime(buy_time_str).time()\n",
    "                sell_time = pd.to_datetime(sell_time_str).time()\n",
    "                \n",
    "                returns = []\n",
    "                \n",
    "                for ticker, df in data_dict.items():\n",
    "                    # Extract time from datetime\n",
    "                    if 'datetime' in df.columns:\n",
    "                        df['time'] = pd.to_datetime(df['datetime']).dt.time\n",
    "                    \n",
    "                    # Find prices at buy/sell times\n",
    "                    buy_mask = df['time'] == buy_time\n",
    "                    sell_mask = df['time'] == sell_time\n",
    "                    \n",
    "                    if buy_mask.any() and sell_mask.any():\n",
    "                        buy_price = df.loc[buy_mask, 'close'].iloc[0]\n",
    "                        sell_price = df.loc[sell_mask, 'close'].iloc[0]\n",
    "                        \n",
    "                        if buy_price > 0:\n",
    "                            ret = (sell_price - buy_price) / buy_price\n",
    "                            returns.append(ret)\n",
    "                \n",
    "                if len(returns) >= CONFIG['MIN_TICKERS_PER_WINDOW']:\n",
    "                    returns_array = np.array(returns)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    avg_return = np.mean(returns_array)\n",
    "                    median_return = np.median(returns_array)\n",
    "                    std_return = np.std(returns_array)\n",
    "                    \n",
    "                    # Win rate\n",
    "                    win_rate = (returns_array > 0).mean()\n",
    "                    \n",
    "                    # Sharpe ratio (not annualized)\n",
    "                    sharpe = avg_return / std_return if std_return > 0 else 0\n",
    "                    \n",
    "                    # Sortino ratio (downside deviation)\n",
    "                    downside_returns = returns_array[returns_array < 0]\n",
    "                    if len(downside_returns) > 0:\n",
    "                        downside_std = np.std(downside_returns)\n",
    "                        sortino = avg_return / downside_std if downside_std > 0 else 0\n",
    "                    else:\n",
    "                        sortino = np.inf if avg_return > 0 else 0\n",
    "                    \n",
    "                    # Max drawdown\n",
    "                    max_drawdown = np.min(returns_array)\n",
    "                    \n",
    "                    # Duration\n",
    "                    duration = (datetime.strptime(sell_time_str, '%H:%M') - \n",
    "                              datetime.strptime(buy_time_str, '%H:%M')).seconds / 3600\n",
    "                    \n",
    "                    results.append({\n",
    "                        'window': f\"{buy_time_str}-{sell_time_str}\",\n",
    "                        'buy_time': buy_time_str,\n",
    "                        'sell_time': sell_time_str,\n",
    "                        'duration_hrs': duration,\n",
    "                        'n_tickers': len(returns),\n",
    "                        'avg_return': avg_return * 100,  # Convert to percentage\n",
    "                        'median_return': median_return * 100,\n",
    "                        'std_return': std_return * 100,\n",
    "                        'win_rate': win_rate * 100,\n",
    "                        'sharpe': sharpe,\n",
    "                        'sortino': sortino if sortino != np.inf else 999,\n",
    "                        'max_drawdown': max_drawdown * 100,\n",
    "                        'return_per_hour': (avg_return * 100) / duration if duration > 0 else 0\n",
    "                    })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Convert to DataFrame and sort by average return\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('avg_return', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Optimize on training set\n",
    "print(\"\\nüéØ Optimizing entry/exit times on TRAINING set...\")\n",
    "train_results = analyze_trading_windows(train_data, \"Training optimization\")\n",
    "\n",
    "# Save results\n",
    "train_results.to_csv(output_dir / 'analysis' / 'train_optimization.csv', index=False)\n",
    "\n",
    "# Display top strategies\n",
    "print(\"\\nüèÜ TOP 10 STRATEGIES (Training Set):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in train_results.head(10).iterrows():\n",
    "    print(f\"{idx+1:2d}. {row['window']:12s} | \"\n",
    "          f\"Return: {row['avg_return']:+6.2f}% | \"\n",
    "          f\"Win: {row['win_rate']:5.1f}% | \"\n",
    "          f\"Sharpe: {row['sharpe']:+6.2f} | \"\n",
    "          f\"Sortino: {row['sortino']:+6.2f} | \"\n",
    "          f\"n={int(row['n_tickers'])}\")\n",
    "\n",
    "# Identify optimal strategy\n",
    "optimal_strategy = train_results.iloc[0]\n",
    "print(f\"\\nüíé OPTIMAL STRATEGY: {optimal_strategy['window']}\")\n",
    "print(f\"   Entry: {optimal_strategy['buy_time']} | Exit: {optimal_strategy['sell_time']}\")\n",
    "print(f\"   Expected return: {optimal_strategy['avg_return']:.2f}%\")\n",
    "print(f\"   Win rate: {optimal_strategy['win_rate']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Validation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"\\nüß™ Validating strategies on TEST set (out-of-sample)...\")\n",
    "test_results = analyze_trading_windows(test_data, \"Test validation\")\n",
    "\n",
    "# Save test results\n",
    "test_results.to_csv(output_dir / 'analysis' / 'test_validation.csv', index=False)\n",
    "\n",
    "# Compare performance of optimal strategy\n",
    "optimal_window = optimal_strategy['window']\n",
    "\n",
    "# Find the same window in test results\n",
    "test_optimal = test_results[test_results['window'] == optimal_window]\n",
    "\n",
    "if not test_optimal.empty:\n",
    "    test_optimal = test_optimal.iloc[0]\n",
    "    \n",
    "    print(\"\\nüìä OPTIMAL STRATEGY PERFORMANCE COMPARISON:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Window: {optimal_window}\")\n",
    "    print(f\"\\nTraining Set Performance:\")\n",
    "    print(f\"   Return: {optimal_strategy['avg_return']:+.2f}%\")\n",
    "    print(f\"   Win Rate: {optimal_strategy['win_rate']:.1f}%\")\n",
    "    print(f\"   Sharpe: {optimal_strategy['sharpe']:.2f}\")\n",
    "    print(f\"   Sortino: {optimal_strategy['sortino']:.2f}\")\n",
    "    \n",
    "    print(f\"\\nTest Set Performance (Out-of-Sample):\")\n",
    "    print(f\"   Return: {test_optimal['avg_return']:+.2f}%\")\n",
    "    print(f\"   Win Rate: {test_optimal['win_rate']:.1f}%\")\n",
    "    print(f\"   Sharpe: {test_optimal['sharpe']:.2f}\")\n",
    "    print(f\"   Sortino: {test_optimal['sortino']:.2f}\")\n",
    "    \n",
    "    # Calculate performance degradation\n",
    "    perf_diff = test_optimal['avg_return'] - optimal_strategy['avg_return']\n",
    "    \n",
    "    if perf_diff < 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Performance degradation: {abs(perf_diff):.2f}% (expected in out-of-sample)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Performance improvement: {perf_diff:.2f}% (lucky!)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Could not find window {optimal_window} in test results\")\n",
    "\n",
    "# Show top performers in test set\n",
    "print(\"\\nüèÜ TOP 10 STRATEGIES (Test Set):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, row in test_results.head(10).iterrows():\n",
    "    print(f\"{idx+1:2d}. {row['window']:12s} | \"\n",
    "          f\"Return: {row['avg_return']:+6.2f}% | \"\n",
    "          f\"Win: {row['win_rate']:5.1f}% | \"\n",
    "          f\"Sharpe: {row['sharpe']:+6.2f} | \"\n",
    "          f\"Sortino: {row['sortino']:+6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ S&P 500 Benchmark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_benchmark():\n",
    "    \"\"\"Download S&P 500 (SPY) data for benchmark comparison\"\"\"\n",
    "    \n",
    "    print(\"üìä Downloading S&P 500 benchmark data...\")\n",
    "    \n",
    "    # Get date range from IPO universe\n",
    "    start_date = ipo_universe['IPO_Date'].min()\n",
    "    end_date = pd.Timestamp(CONFIG['END_DATE'])\n",
    "    \n",
    "    # Download SPY data\n",
    "    spy = yf.download('SPY', start=start_date, end=end_date, progress=False)\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    spy['Return'] = spy['Adj Close'].pct_change()\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    spy['Cumulative'] = (1 + spy['Return']).cumprod()\n",
    "    \n",
    "    print(f\"‚úì Downloaded {len(spy)} days of SPY data\")\n",
    "    print(f\"   Period: {start_date.date()} to {end_date.date()}\")\n",
    "    \n",
    "    # Calculate benchmark statistics\n",
    "    total_return = (spy['Cumulative'].iloc[-1] - 1) * 100\n",
    "    annual_days = 252\n",
    "    years = len(spy) / annual_days\n",
    "    \n",
    "    # Simple average return (not annualized)\n",
    "    avg_daily_return = spy['Return'].mean() * 100\n",
    "    \n",
    "    # Risk metrics\n",
    "    daily_std = spy['Return'].std() * 100\n",
    "    sharpe = (spy['Return'].mean() / spy['Return'].std()) if spy['Return'].std() > 0 else 0\n",
    "    \n",
    "    # Max drawdown\n",
    "    cummax = spy['Cumulative'].cummax()\n",
    "    drawdown = (spy['Cumulative'] - cummax) / cummax\n",
    "    max_drawdown = drawdown.min() * 100\n",
    "    \n",
    "    # Sortino ratio\n",
    "    downside_returns = spy['Return'][spy['Return'] < 0]\n",
    "    downside_std = downside_returns.std()\n",
    "    sortino = spy['Return'].mean() / downside_std if downside_std > 0 else 0\n",
    "    \n",
    "    benchmark_stats = {\n",
    "        'total_return': total_return,\n",
    "        'years': years,\n",
    "        'avg_daily_return': avg_daily_return,\n",
    "        'daily_std': daily_std,\n",
    "        'sharpe': sharpe,\n",
    "        'sortino': sortino,\n",
    "        'max_drawdown': max_drawdown\n",
    "    }\n",
    "    \n",
    "    return spy, benchmark_stats\n",
    "\n",
    "# Get benchmark data\n",
    "spy_data, spy_stats = get_sp500_benchmark()\n",
    "\n",
    "print(\"\\nüìà S&P 500 BENCHMARK STATISTICS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Return: {spy_stats['total_return']:+.2f}%\")\n",
    "print(f\"Period: {spy_stats['years']:.1f} years\")\n",
    "print(f\"Avg Daily Return: {spy_stats['avg_daily_return']:+.4f}%\")\n",
    "print(f\"Daily Volatility: {spy_stats['daily_std']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {spy_stats['sharpe']:.2f}\")\n",
    "print(f\"Sortino Ratio: {spy_stats['sortino']:.2f}\")\n",
    "print(f\"Max Drawdown: {spy_stats['max_drawdown']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ $100K Portfolio Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_portfolio(universe, data_dict, strategy_window):\n",
    "    \"\"\"Simulate $100K portfolio using optimal strategy\"\"\"\n",
    "    \n",
    "    print(f\"\\nüí∞ Simulating ${CONFIG['INITIAL_CAPITAL']:,} portfolio...\")\n",
    "    print(f\"   Strategy: {strategy_window}\")\n",
    "    \n",
    "    # Parse strategy\n",
    "    buy_time_str, sell_time_str = strategy_window.split('-')\n",
    "    buy_time = pd.to_datetime(buy_time_str).time()\n",
    "    sell_time = pd.to_datetime(sell_time_str).time()\n",
    "    \n",
    "    # Track portfolio performance\n",
    "    portfolio_value = CONFIG['INITIAL_CAPITAL']\n",
    "    trades = []\n",
    "    portfolio_history = []\n",
    "    \n",
    "    # Process IPOs chronologically\n",
    "    universe_sorted = universe.sort_values('IPO_Date')\n",
    "    \n",
    "    for _, ipo in universe_sorted.iterrows():\n",
    "        ticker = ipo['Ticker']\n",
    "        \n",
    "        if ticker not in data_dict:\n",
    "            continue\n",
    "        \n",
    "        df = data_dict[ticker]\n",
    "        \n",
    "        # Extract time\n",
    "        if 'datetime' in df.columns:\n",
    "            df['time'] = pd.to_datetime(df['datetime']).dt.time\n",
    "        \n",
    "        # Find prices\n",
    "        buy_mask = df['time'] == buy_time\n",
    "        sell_mask = df['time'] == sell_time\n",
    "        \n",
    "        if buy_mask.any() and sell_mask.any():\n",
    "            buy_price = df.loc[buy_mask, 'close'].iloc[0]\n",
    "            sell_price = df.loc[sell_mask, 'close'].iloc[0]\n",
    "            \n",
    "            if buy_price > 0:\n",
    "                # Calculate position size (equal weight)\n",
    "                position_size = portfolio_value * 0.05  # 5% per trade max\n",
    "                shares = position_size / buy_price\n",
    "                \n",
    "                # Calculate P&L\n",
    "                pnl = shares * (sell_price - buy_price)\n",
    "                pnl_pct = (sell_price - buy_price) / buy_price * 100\n",
    "                \n",
    "                # Update portfolio\n",
    "                portfolio_value += pnl\n",
    "                \n",
    "                # Record trade\n",
    "                trades.append({\n",
    "                    'date': ipo['IPO_Date'],\n",
    "                    'ticker': ticker,\n",
    "                    'buy_price': buy_price,\n",
    "                    'sell_price': sell_price,\n",
    "                    'shares': shares,\n",
    "                    'pnl': pnl,\n",
    "                    'pnl_pct': pnl_pct,\n",
    "                    'portfolio_value': portfolio_value\n",
    "                })\n",
    "                \n",
    "                portfolio_history.append({\n",
    "                    'date': ipo['IPO_Date'],\n",
    "                    'value': portfolio_value,\n",
    "                    'return': (portfolio_value / CONFIG['INITIAL_CAPITAL'] - 1) * 100\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    portfolio_df = pd.DataFrame(portfolio_history)\n",
    "    \n",
    "    # Calculate portfolio statistics\n",
    "    if not trades_df.empty:\n",
    "        total_return = (portfolio_value / CONFIG['INITIAL_CAPITAL'] - 1) * 100\n",
    "        win_rate = (trades_df['pnl'] > 0).mean() * 100\n",
    "        avg_trade = trades_df['pnl_pct'].mean()\n",
    "        \n",
    "        # Calculate max drawdown\n",
    "        portfolio_df['cummax'] = portfolio_df['value'].cummax()\n",
    "        portfolio_df['drawdown'] = (portfolio_df['value'] - portfolio_df['cummax']) / portfolio_df['cummax']\n",
    "        max_drawdown = portfolio_df['drawdown'].min() * 100\n",
    "        \n",
    "        portfolio_stats = {\n",
    "            'initial_capital': CONFIG['INITIAL_CAPITAL'],\n",
    "            'final_value': portfolio_value,\n",
    "            'total_return': total_return,\n",
    "            'total_trades': len(trades_df),\n",
    "            'win_rate': win_rate,\n",
    "            'avg_trade_return': avg_trade,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'best_trade': trades_df['pnl_pct'].max(),\n",
    "            'worst_trade': trades_df['pnl_pct'].min()\n",
    "        }\n",
    "    else:\n",
    "        portfolio_stats = {\n",
    "            'initial_capital': CONFIG['INITIAL_CAPITAL'],\n",
    "            'final_value': portfolio_value,\n",
    "            'total_return': 0,\n",
    "            'total_trades': 0\n",
    "        }\n",
    "    \n",
    "    return trades_df, portfolio_df, portfolio_stats\n",
    "\n",
    "# Combine all data for full simulation\n",
    "all_data = {**train_data, **test_data}\n",
    "\n",
    "# Run portfolio simulation\n",
    "trades_df, portfolio_df, portfolio_stats = simulate_portfolio(\n",
    "    ipo_universe, \n",
    "    all_data, \n",
    "    optimal_strategy['window']\n",
    ")\n",
    "\n",
    "# Save trade history\n",
    "trades_df.to_csv(output_dir / 'analysis' / 'trade_history.csv', index=False)\n",
    "portfolio_df.to_csv(output_dir / 'analysis' / 'portfolio_history.csv', index=False)\n",
    "\n",
    "print(\"\\nüíº PORTFOLIO SIMULATION RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Initial Capital: ${portfolio_stats['initial_capital']:,}\")\n",
    "print(f\"Final Value: ${portfolio_stats['final_value']:,.2f}\")\n",
    "print(f\"Total Return: {portfolio_stats['total_return']:+.2f}%\")\n",
    "print(f\"Total Trades: {portfolio_stats['total_trades']}\")\n",
    "print(f\"Win Rate: {portfolio_stats.get('win_rate', 0):.1f}%\")\n",
    "print(f\"Avg Trade Return: {portfolio_stats.get('avg_trade_return', 0):+.2f}%\")\n",
    "print(f\"Max Drawdown: {portfolio_stats.get('max_drawdown', 0):.2f}%\")\n",
    "print(f\"Best Trade: {portfolio_stats.get('best_trade', 0):+.2f}%\")\n",
    "print(f\"Worst Trade: {portfolio_stats.get('worst_trade', 0):.2f}%\")\n",
    "\n",
    "# Compare to S&P 500\n",
    "print(\"\\nüìä STRATEGY VS S&P 500 COMPARISON:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"                    Strategy     S&P 500\")\n",
    "print(f\"Total Return:      {portfolio_stats['total_return']:+8.2f}%   {spy_stats['total_return']:+8.2f}%\")\n",
    "print(f\"Max Drawdown:      {portfolio_stats.get('max_drawdown', 0):8.2f}%   {spy_stats['max_drawdown']:8.2f}%\")\n",
    "\n",
    "outperformance = portfolio_stats['total_return'] - spy_stats['total_return']\n",
    "if outperformance > 0:\n",
    "    print(f\"\\n‚úÖ Strategy OUTPERFORMED S&P 500 by {outperformance:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Strategy UNDERPERFORMED S&P 500 by {abs(outperformance):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Visualization & Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = GridSpec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Portfolio Performance vs S&P 500\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "if not portfolio_df.empty:\n",
    "    ax1.plot(pd.to_datetime(portfolio_df['date']), portfolio_df['return'], \n",
    "             label='IPO Strategy', linewidth=2, color='blue')\n",
    "\n",
    "# Add S&P 500\n",
    "spy_return = (spy_data['Cumulative'] - 1) * 100\n",
    "ax1.plot(spy_return.index, spy_return.values, \n",
    "         label='S&P 500', linewidth=2, color='red', alpha=0.7)\n",
    "\n",
    "ax1.set_title('Portfolio Performance: IPO Strategy vs S&P 500', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Cumulative Return (%)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Train vs Test Performance\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "comparison_data = {\n",
    "    'Training': optimal_strategy['avg_return'],\n",
    "    'Test': test_optimal['avg_return'] if 'test_optimal' in locals() and not pd.isna(test_optimal['avg_return']) else 0\n",
    "}\n",
    "bars = ax2.bar(comparison_data.keys(), comparison_data.values(), color=['green', 'orange'])\n",
    "ax2.set_title('Strategy Performance: Train vs Test', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average Return (%)')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, comparison_data.values()):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{val:.2f}%', ha='center', va='bottom' if val > 0 else 'top')\n",
    "\n",
    "# 3. Win Rate Distribution\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.hist(train_results['win_rate'], bins=20, alpha=0.7, label='Training', color='blue')\n",
    "ax3.hist(test_results['win_rate'], bins=20, alpha=0.7, label='Test', color='red')\n",
    "ax3.set_title('Win Rate Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Win Rate (%)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.legend()\n",
    "ax3.axvline(x=50, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. Risk Metrics Comparison\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "metrics = ['Sharpe', 'Sortino', 'Max DD']\n",
    "strategy_metrics = [\n",
    "    optimal_strategy['sharpe'],\n",
    "    optimal_strategy['sortino'] if optimal_strategy['sortino'] < 100 else 10,\n",
    "    abs(optimal_strategy['max_drawdown'])\n",
    "]\n",
    "spy_metrics = [\n",
    "    spy_stats['sharpe'],\n",
    "    spy_stats['sortino'],\n",
    "    abs(spy_stats['max_drawdown'])\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, strategy_metrics, width, label='IPO Strategy', color='blue')\n",
    "ax4.bar(x + width/2, spy_metrics, width, label='S&P 500', color='red')\n",
    "ax4.set_title('Risk Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(metrics)\n",
    "ax4.legend()\n",
    "\n",
    "# 5. Top Windows Heatmap\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "pivot_data = train_results.pivot_table(\n",
    "    values='avg_return',\n",
    "    index='buy_time',\n",
    "    columns='sell_time',\n",
    "    aggfunc='first'\n",
    ")\n",
    "sns.heatmap(pivot_data, cmap='RdYlGn', center=0, ax=ax5, \n",
    "            cbar_kws={'label': 'Avg Return (%)'}, fmt='.1f')\n",
    "ax5.set_title('Trading Windows Heatmap (Training Set)', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Exit Time')\n",
    "ax5.set_ylabel('Entry Time')\n",
    "\n",
    "plt.suptitle('IPO Farming Strategy - Complete Backtest Analysis', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(output_dir / 'visualizations' / 'complete_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualizations saved to outputs/visualizations/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Generate PDF Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf_report():\n",
    "    \"\"\"Generate professional PDF report with all results\"\"\"\n",
    "    \n",
    "    print(\"\\nüìÑ Generating PDF report...\")\n",
    "    \n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image\n",
    "    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "    from reportlab.lib import colors\n",
    "    from reportlab.lib.units import inch\n",
    "    \n",
    "    # Create PDF\n",
    "    pdf_path = output_dir / 'reports' / 'backtest_report.pdf'\n",
    "    doc = SimpleDocTemplate(str(pdf_path), pagesize=letter)\n",
    "    story = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    # Title\n",
    "    title_style = ParagraphStyle(\n",
    "        'CustomTitle',\n",
    "        parent=styles['Title'],\n",
    "        fontSize=24,\n",
    "        textColor=colors.HexColor('#1f77b4'),\n",
    "        spaceAfter=30\n",
    "    )\n",
    "    story.append(Paragraph(\"IPO Farming Strategy Backtest Report\", title_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Date and configuration\n",
    "    story.append(Paragraph(f\"<b>Test Date:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", styles['Normal']))\n",
    "    story.append(Paragraph(f\"<b>Date Range:</b> {CONFIG['START_YEAR']}-01-01 to {CONFIG['END_DATE']}\", styles['Normal']))\n",
    "    story.append(Paragraph(f\"<b>Initial Capital:</b> ${CONFIG['INITIAL_CAPITAL']:,}\", styles['Normal']))\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Executive Summary\n",
    "    story.append(Paragraph(\"<b>Executive Summary</b>\", styles['Heading2']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    summary_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Total IPOs Analyzed', f\"{len(ipo_universe)}\"],\n",
    "        ['Active Tickers', f\"{len(active_ipos)}\"],\n",
    "        ['Delisted Tickers', f\"{len(delisted_ipos)}\"],\n",
    "        ['Optimal Strategy', f\"{optimal_strategy['window']}\"],\n",
    "        ['Expected Return', f\"{optimal_strategy['avg_return']:.2f}%\"],\n",
    "        ['Win Rate', f\"{optimal_strategy['win_rate']:.1f}%\"],\n",
    "        ['Sharpe Ratio', f\"{optimal_strategy['sharpe']:.2f}\"],\n",
    "        ['Sortino Ratio', f\"{optimal_strategy['sortino']:.2f}\"]\n",
    "    ]\n",
    "    \n",
    "    summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])\n",
    "    summary_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    story.append(summary_table)\n",
    "    story.append(PageBreak())\n",
    "    \n",
    "    # Portfolio Performance\n",
    "    story.append(Paragraph(\"<b>Portfolio Performance</b>\", styles['Heading2']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    performance_data = [\n",
    "        ['Metric', 'IPO Strategy', 'S&P 500'],\n",
    "        ['Total Return', f\"{portfolio_stats['total_return']:.2f}%\", f\"{spy_stats['total_return']:.2f}%\"],\n",
    "        ['Max Drawdown', f\"{portfolio_stats.get('max_drawdown', 0):.2f}%\", f\"{spy_stats['max_drawdown']:.2f}%\"],\n",
    "        ['Sharpe Ratio', f\"{optimal_strategy['sharpe']:.2f}\", f\"{spy_stats['sharpe']:.2f}\"],\n",
    "        ['Sortino Ratio', f\"{optimal_strategy['sortino']:.2f}\", f\"{spy_stats['sortino']:.2f}\"],\n",
    "        ['Total Trades', f\"{portfolio_stats['total_trades']}\", \"N/A\"],\n",
    "        ['Win Rate', f\"{portfolio_stats.get('win_rate', 0):.1f}%\", \"N/A\"]\n",
    "    ]\n",
    "    \n",
    "    performance_table = Table(performance_data, colWidths=[2.5*inch, 2*inch, 2*inch])\n",
    "    performance_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    story.append(performance_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "    \n",
    "    # Add visualization if exists\n",
    "    viz_path = output_dir / 'visualizations' / 'complete_analysis.png'\n",
    "    if viz_path.exists():\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph(\"<b>Performance Visualizations</b>\", styles['Heading2']))\n",
    "        story.append(Spacer(1, 12))\n",
    "        img = Image(str(viz_path), width=7*inch, height=5*inch)\n",
    "        story.append(img)\n",
    "    \n",
    "    # Top strategies table\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph(\"<b>Top 10 Trading Windows</b>\", styles['Heading2']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    top_strategies_data = [['Rank', 'Window', 'Return', 'Win Rate', 'Sharpe', 'Sortino']]\n",
    "    for idx, row in train_results.head(10).iterrows():\n",
    "        top_strategies_data.append([\n",
    "            f\"{idx+1}\",\n",
    "            row['window'],\n",
    "            f\"{row['avg_return']:.2f}%\",\n",
    "            f\"{row['win_rate']:.1f}%\",\n",
    "            f\"{row['sharpe']:.2f}\",\n",
    "            f\"{row['sortino']:.2f}\"\n",
    "        ])\n",
    "    \n",
    "    top_table = Table(top_strategies_data, colWidths=[0.5*inch, 1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])\n",
    "    top_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n",
    "    ]))\n",
    "    story.append(top_table)\n",
    "    \n",
    "    # Disclaimer\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph(\"<b>Disclaimer</b>\", styles['Heading2']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    disclaimer_text = \"\"\"\n",
    "    This report is for informational purposes only and does not constitute financial advice. \n",
    "    Past performance does not guarantee future results. Trading IPOs involves substantial risk, \n",
    "    including the potential loss of principal. Always conduct your own research and consult with \n",
    "    a qualified financial advisor before making investment decisions.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(disclaimer_text, styles['Normal']))\n",
    "    \n",
    "    # Build PDF\n",
    "    doc.build(story)\n",
    "    \n",
    "    print(f\"‚úÖ PDF report saved to: {pdf_path}\")\n",
    "    \n",
    "    return pdf_path\n",
    "\n",
    "if CONFIG['GENERATE_PDF']:\n",
    "    pdf_path = generate_pdf_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Final Summary & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"‚úÖ BACKTEST COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä SUMMARY:\")\n",
    "print(f\"   Test ID: {timestamp}\")\n",
    "print(f\"   IPOs Analyzed: {len(ipo_universe)}\")\n",
    "print(f\"   Date Range: {CONFIG['START_YEAR']} to {CONFIG['END_YEAR']}\")\n",
    "print(f\"   Optimal Strategy: {optimal_strategy['window']}\")\n",
    "print(f\"   Portfolio Return: {portfolio_stats['total_return']:+.2f}%\")\n",
    "print(f\"   S&P 500 Return: {spy_stats['total_return']:+.2f}%\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT LOCATION: {output_dir}\")\n",
    "\n",
    "print(f\"\\nüìÑ FILES GENERATED:\")\n",
    "print(\"   üìÇ config/\")\n",
    "print(\"      ‚Ä¢ test_config.json\")\n",
    "print(\"   üìÇ data/\")\n",
    "print(\"      ‚Ä¢ combined_universe.csv\")\n",
    "print(\"      ‚Ä¢ active_ipos.csv\")\n",
    "print(\"      ‚Ä¢ delisted_ipos.csv\")\n",
    "print(\"   üìÇ analysis/\")\n",
    "print(\"      ‚Ä¢ train_optimization.csv\")\n",
    "print(\"      ‚Ä¢ test_validation.csv\")\n",
    "print(\"      ‚Ä¢ trade_history.csv\")\n",
    "print(\"      ‚Ä¢ portfolio_history.csv\")\n",
    "print(\"   üìÇ visualizations/\")\n",
    "print(\"      ‚Ä¢ complete_analysis.png\")\n",
    "print(\"   üìÇ reports/\")\n",
    "print(\"      ‚Ä¢ backtest_report.pdf\")\n",
    "\n",
    "print(\"\\nüéØ KEY FINDINGS:\")\n",
    "print(f\"   ‚Ä¢ Best Entry Time: {optimal_strategy['buy_time']}\")\n",
    "print(f\"   ‚Ä¢ Best Exit Time: {optimal_strategy['sell_time']}\")\n",
    "print(f\"   ‚Ä¢ Expected Return per Trade: {optimal_strategy['avg_return']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Win Rate: {optimal_strategy['win_rate']:.1f}%\")\n",
    "\n",
    "outperformance = portfolio_stats['total_return'] - spy_stats['total_return']\n",
    "if outperformance > 0:\n",
    "    print(f\"\\nüèÜ Strategy OUTPERFORMED S&P 500 by {outperformance:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\nüìâ Strategy UNDERPERFORMED S&P 500 by {abs(outperformance):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Thank you for using the IPO Farming Backtest System!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}